{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n82rbx94zeEq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet\n",
        "ResNet, short for Residual Networks, is a type of deep learning model introduced by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun in their 2015 paper \"Deep Residual Learning for Image Recognition\". The model was developed for the purpose of making the training of deep neural networks easier and more efficient.\n",
        "\n",
        "ResNet introduced the concept of residual learning to address the vanishing gradient problem faced by deep neural networks. In these networks, as the number of layers increases, the performance starts to degrade due to the problem of vanishing or exploding gradients. This makes the network difficult to train, and the accuracy starts getting saturated or even degraded rapidly.\n",
        "\n",
        "ResNet solves this issue by introducing 'skip connections' or 'shortcuts' that allow the gradient to be directly backpropagated to earlier layers. These shortcuts are connections that skip one or more layers. The key insight of ResNet is realizing that it's easier to optimize the residual mapping than the original, unreferenced mapping.\n",
        "\n",
        "The core idea of ResNet is the introduction of the so-called \"identity shortcut connection\" that skips one or more layers, as shown in their research:\n",
        "\n",
        "`output = F(x) + x`\n",
        "\n",
        "Here, `F(x)` represents the underlying mapping to be learned by any stack of layers, and `x` is the identity mapping. If `F(x)` is the residual mapping, then it's easier to push the residual to zero than to fit an original, unreferenced mapping.\n",
        "\n",
        "There are several variants of ResNet such as ResNet-18, ResNet-34, ResNet-50, ResNet-101, and ResNet-152, where the numbers denote layers in the network. ResNet models, particularly ResNet-50, are widely used in many deep learning applications because they provide high accuracy and are relatively computationally efficient.\n",
        "\n",
        "In terms of use cases, ResNet has been effectively used for a wide variety of tasks including image classification, object detection, and recognition tasks.\n"
      ],
      "metadata": {
        "id": "AMYE-wi8z6fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet-50\n",
        "ResNet-50 is a variant of the original ResNet architecture, which stands for Residual Network. It is a convolutional neural network (CNN) architecture that was designed to enable the creation of deeper networks while mitigating the issues of vanishing gradients during training, as we have discussed before. \n",
        "\n",
        "The number \"50\" in ResNet-50 refers to the depth of the network, that is, it has 50 layers including both convolutional and fully connected layers. It follows the same concept of using shortcut (or skip) connections like other ResNets, but it also uses a concept called \"bottleneck design\" for constructing the blocks of layers.\n",
        "\n",
        "The ResNet-50 architecture can be broken down as follows:\n",
        "\n",
        "1. **Initial Convolution and Max Pooling Layers**: The input images first pass through a single 7x7 convolutional layer with 64 filters, followed by a batch normalization layer, a ReLU activation function, and a max pooling layer.\n",
        "\n",
        "2. **Bottleneck Blocks**: The heart of the ResNet-50 architecture consists of four stages, each composed of a number of bottleneck blocks (which include three layers each). These are the residual blocks that give ResNet its name. \n",
        "\n",
        "    - The first stage has 3 blocks, with the number of filters being 64, 64, and 256 respectively. \n",
        "    - The second stage has 4 blocks, with the number of filters being 128, 128, and 512 respectively. \n",
        "    - The third stage has 6 blocks, with the number of filters being 256, 256, and 1024 respectively. \n",
        "    - The fourth stage has 3 blocks, with the number of filters being 512, 512, and 2048 respectively. \n",
        "\n",
        "    Note: For the first block of each stage, if the output size (height, width) is reduced, a convolutional layer with stride 2 is applied in the shortcut connection to match the size and number of filters of the output.\n",
        "\n",
        "3. **Final Layers**: After the bottleneck blocks, a global average pooling layer is applied, followed by a fully connected layer with 1000 neurons (for the ImageNet classification task), and a softmax activation function to generate the output probabilities.\n",
        "\n",
        "ResNet-50, like other ResNet variants, is widely used in both academia and industry for a large number of image classification tasks due to its excellent performance and the generalizability of its learned features."
      ],
      "metadata": {
        "id": "sV54G0dJ-KHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Residual Block\n",
        "A residual block, or res-block, is the fundamental building block of a ResNet. The design of a residual block is rooted in the idea of learning the residual function with reference to the input, rather than learning the original unreferenced function.\n",
        "\n",
        "In its simplest form, a residual block consists of several convolutional layers, followed by batch normalization and a ReLU (Rectified Linear Unit) activation function. The input to the block is added to the output of the block (before the final activation function), forming a 'shortcut' or 'skip connection'. This allows the gradient to be directly backpropagated to earlier layers.\n",
        "\n",
        "Here's the basic structure of a Residual Block:\n",
        "\n",
        "1. Convolutional layer: Applies a convolution operation on the input and passes the result to the next layer.\n",
        "2. Batch normalization: Normalizes the activations of the previous layer at each batch to increase the stability and performance of the neural network.\n",
        "3. ReLU activation: Applies the Rectified Linear Unit activation function which is max(0, x), where x is the input. It effectively removes negative values and introduces non-linearity without affecting the receptive fields of the conv layer.\n",
        "4. Another sequence of Convolutional layer, Batch normalization, and then instead of applying ReLU activation, we add the initial input ('skip connection') to the output of the convolution block.\n",
        "5. ReLU activation: Now apply the activation function to the result of the addition.\n",
        "\n",
        "The skip connection allows the model to bypass layers during training: the network can propagate gradients directly through the shortcut connections, without any modification, to deeper layers in the network. This mitigates the vanishing/exploding gradient problem associated with deep neural networks, making it possible to train much deeper networks.\n",
        "\n",
        "A crucial detail to mention is that if the dimensions of the input and the output of the residual block don't match (which can happen due to operations like convolution or pooling that modify the input dimensions), a linear projection can be used in the skip connection to match the dimensions. This projection can be accomplished via a 1x1 convolution.\n",
        "\n",
        "The use of residual blocks makes it possible to train very deep networks (100+ layers), which would be very challenging with traditional architectures due to issues like vanishing and exploding gradients."
      ],
      "metadata": {
        "id": "iW2xgTbq0X7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skip Connections:\n",
        "\n",
        "Skip connections, also known as shortcut connections, are a key feature of ResNet architectures that help address the problem of vanishing/exploding gradients in deep neural networks.\n",
        "\n",
        "In a deep network, the output of one layer is used as the input to the next layer. However, in a network with skip connections, the input to a layer is also added to the output of that layer (or some subsequent layer). The 'skipped' input can be thought of as a shortcut in the network, allowing the gradient from the loss function to be directly backpropagated to earlier layers.\n",
        "\n",
        "Skip connections have two key benefits:\n",
        "\n",
        "1. They mitigate the vanishing gradient problem, making it easier to train deep networks. By providing a path for the gradient that bypasses several layers, they prevent the gradient from becoming infinitesimally small (and thus ineffective for training) in the early layers of the network.\n",
        "\n",
        "2. They allow the network to learn identity functions, which can be useful when the optimal function is close to the identity. In other words, they make it easier for a layer to learn to produce output that is identical to its input, which is useful when the input is already a good representation for the task at hand.\n",
        "\n",
        "In the original ResNet architecture, every layer's output is added to the output of the layer that is two layers further along in the network (after the two have gone through their respective ReLU activation functions). This is done using skip (or shortcut) connections, which bypass one layer (in this case, a 3-layer convolution block). So, essentially, the output of a previous layer is added to the output of the layer two steps ahead.\n",
        "\n",
        "To be more specific, if we number the layers starting from 1, then for any given layer 'n', a skip connection is established from the output of layer 'n' to the input of layer 'n+2'. \n",
        "\n",
        "This is not a hard and fast rule, though. Skip connections can be implemented in different ways depending on the specific architecture and design choices. For instance, in a DenseNet (another type of Residual Network), each layer receives input from all preceding layers.\n",
        "\n",
        "One of the primary considerations in deciding where to place skip connections is the desire to mitigate the vanishing gradient problem. This problem becomes more severe the deeper the network is, so skip connections are typically more beneficial in deeper networks.\n",
        "\n",
        "However, the actual placement of these connections can also depend on other factors, such as computational resources and the specific task at hand. Some experimentation might be necessary to find the optimal architecture for a given problem. \n",
        "\n",
        "In general, the ResNet architecture, which includes a skip connection every two layers, has been found to work well for a wide range of tasks and is a good starting point.\n",
        "\n",
        "## Bottleneck Design:\n",
        "\n",
        "The bottleneck design is a modification of the basic residual block in ResNet, used to make the network more efficient. This design was introduced in the deeper versions of ResNet, like ResNet-50, 101, and 152.\n",
        "\n",
        "In the bottleneck design, instead of having two 3x3 conv layers (as in the basic block), the block has three layers: a 1x1 conv layer, a 3x3 conv layer, and another 1x1 conv layer. The 1x1 convolutions are used to reduce and then restore the dimensions of the input, leading to fewer input-output channel dimensions and therefore fewer parameters and computations. \n",
        "\n",
        "In terms of sequence:\n",
        "\n",
        "1. The first 1x1 convolution reduces the dimensionality (depth) before passing it to the more expensive 3x3 convolution.\n",
        "2. The 3x3 convolution operates on a smaller input and produces a similarly small output.\n",
        "3. The final 1x1 convolution restores the dimensionality back to match the original depth.\n",
        "\n",
        "This is where the term \"bottleneck\" comes from: the network depth decreases and then increases, with the shallowest point being in the middle of the block, giving it a \"bottleneck\" shape. \n",
        "\n",
        "The bottleneck design significantly reduces computational cost, allowing for deeper and more efficient networks."
      ],
      "metadata": {
        "id": "o6yDDugI0rl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "aFdsHlV82Xby"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBNLayer(torch.nn.Module):\n",
        "  def __init__(self,num_channels,num_filters,filters_size,stride=1, groups=1,act=None):\n",
        "    \"\"\"\n",
        "      num_channels, input channels for the convolutional layer\n",
        "      num_filters, output channels for the convolutional layer\n",
        "      stride, stride for the convolutional layer\n",
        "      groups, number of groups for grouped convolution, default is groups=1 which means no grouped convolution\n",
        "    \"\"\"\n",
        "    super(ConvBNLayer,self).__init__()\n",
        "    #The amount of padding required to keep the output size the same as the input size depends on the filter size, \n",
        "    #and it is given by (filter_size - 1) // 2 when the stride is 1.\n",
        "    self._conv=nn.Conv2d(in_channels=num_channels,out_channels=num_filters,\n",
        "                         kernel_size=filters_size, stride=stride,\n",
        "                         padding=(filters_size-1)//2, groups=groups, bias=False)\n",
        "    \n",
        "    self._batch_norm=nn.BatchNorm2d(num_filters)\n",
        "    self.act=act\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    y=self._conv(inputs)\n",
        "    y=self._batch_norm(y)\n",
        "    #introduce non-linearity into the model\n",
        "    if self.act=='leaky':\n",
        "      y=F.leaky_relu(input=y,negative_slope=0.1)\n",
        "    elif self.act=='relu':\n",
        "      y=F.relu(input=y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "H7OXFXpl2pS_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leaky Relu\n",
        "Leaky ReLU is a variation of ReLU that has a small slope for negative values instead of a flat slope, hence the term 'leaky'. The slope is controlled by the negative_slope parameter and is typically a small, positive number like 0.01. This means that negative inputs result in a small negative output, rather than zero, which can help mitigate the issue of 'dead' neurons."
      ],
      "metadata": {
        "id": "WRg403-Y5e-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleneckBlock(torch.nn.Module):\n",
        "  def __init__(self,num_channels,num_filters,stride,shortcut=True):\n",
        "    super(BottleneckBlock,self).__init__()\n",
        "    # Create the first convolutional layer (1x1)\n",
        "    self.conv1=ConvBNLayer(num_channels=num_filters,num_filters=num_filters,filters_size=3,stride=stride,act='relu')\n",
        "    # Create the second convolutional layer (3x3)\n",
        "    self.conv2=ConvBNLayer(num_channels=num_filters,num_filters=num_filters,filters_size=3,stride=stride,act='relu')\n",
        "    # Create the third convolutional layer (1x1), but the number of output channels is multiplied by 4\n",
        "    # preparing the output to be added to the shortcut connection.\n",
        "    self.conv3=ConvBNLayer(num_channels=num_filters,num_filters=num_filters*4,filters_size=1,act=None)\n",
        "\n",
        "\n",
        "    # If the output shape of conv3 is the same as the input to this residual block, then shortcut=True\n",
        "    # Otherwise, shortcut=False, and add a 1x1 convolution to the input to make its shape the same as conv3\n",
        "\n",
        "    if not shortcut:\n",
        "      #adjust the number and size of the channels in the input \n",
        "      #so that it can be added to the output of conv3\n",
        "      self.short=ConvBNLayer(num_channels=num_channels,num_filters=num_filters*4,filters_size=1,stride=stride)\n",
        "\n",
        "    self.shortcut=shortcut\n",
        "    self._num_channels_out=num_filters*4\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    y=self.conv1(inputs)\n",
        "    conv1=self.conv2(y)\n",
        "    conv2=self.conv3(conv1)\n",
        "\n",
        "    if self.shortcut:\n",
        "      short=inputs\n",
        "    else:\n",
        "      short=self.short(inputs)\n",
        "\n",
        "    y=torch.add(short,conv2)\n",
        "    y=F.relu(y)\n",
        "    return y\n",
        "\n"
      ],
      "metadata": {
        "id": "H_XGdtKz54vm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import ParameterDict\n",
        "from torch.nn.modules.pooling import AdaptiveAvgPool2d\n",
        "import numpy as np\n",
        "\n",
        "class ResNet(torch.nn.Module):\n",
        "  def __init__(self,layers=50,class_dim=1):\n",
        "    \"\"\"\n",
        "        layers, the depth of the ResNet model (50, 101, or 152)\n",
        "        class_dim, the number of output classes for the final layer\n",
        "    \"\"\"\n",
        "    super(ResNet,self).__init__()\n",
        "    self.layers=layers\n",
        "    supported_layers=[50,101,152]\n",
        "    assert layers in supported_layers,\\\n",
        "    \"supported layers are {} but input layers is {}\".format(supported_layers,layers)\n",
        "\n",
        "    #define the number of bottleneck blocks in each layer (depth) and\n",
        "    #the number of filters for each layer.\n",
        "\n",
        "    if layers==50:\n",
        "      #ResNet50包含多个模块，其中第2到第5个模块分别包含3、4、6、3个残差块\n",
        "      depth=[3,4,6,3]\n",
        "    elif layers==101:\n",
        "      #ResNet101包含多个模块，其中第2到第5个模块分别包含3、4、23、3个残差块\n",
        "      depth=[3,4,23,3]\n",
        "    elif layers==152:\n",
        "      #ResNet152包含多个模块，其中第2到第5个模块分别包含3、8、36、3个残差块\n",
        "      depth=[3,8,36,3]\n",
        "\n",
        "    # 残差块中使用到的卷积的输出通道数\n",
        "    num_filters=[64,128,256,512]\n",
        "\n",
        "    #the initial convolutional layer that processes the input image\n",
        "    self.conv=ConvBNLayer(num_channels=3,num_filters=64,filters_size=7,stride=2,act='relu')\n",
        "    #max pooling layer to reduce the spatial dimensions of the tensor\n",
        "    self.pool2d_max=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "\n",
        "    # ResNet的第二到第五个模块c2、c3、c4、c5\n",
        "    #initializes a ModuleList to hold the bottleneck blocks\n",
        "    self.bottleneck_block_list=nn.ModuleList()\n",
        "    num_channels=64\n",
        "    for block in range(len(depth)):\n",
        "      shortcut=False\n",
        "      for i in range(depth[block]):\n",
        "        # c3、c4、c5将会在第一个残差块使用stride=2；其余所有残差块stride=1\n",
        "        # multiple BottleneckBlock modules are created according to the depth array\n",
        "        bottleneck_block = BottleneckBlock(num_channels=num_channels, num_filters=num_filters[block], \n",
        "                                           stride=2 if i == 0 and block != 0 else 1, shortcut=shortcut)\n",
        "        #The num_channels is updated for the next block\n",
        "        num_channels = bottleneck_block._num_channels_out\n",
        "        #added to self.bottleneck_block_list\n",
        "        self.bottleneck_block_list.append(bottleneck_block)\n",
        "        shortcut = True\n",
        "\n",
        "    # 在c5的输出特征图上使用全局池化\n",
        "    # adaptive average pooling layer at the end of the network\n",
        "    # reduces the height and width dimensions of each feature map to 1, effectively performing global average pooling.\n",
        "    self.pool2d_avg=nn.AdaptiveAvgPool2d(output_size=1)\n",
        "\n",
        "    # stdv用来作为全连接层随机初始化参数的方差\n",
        "    # calculates the standard deviation (stdv) for initializing the weights of the final fully connected layer\n",
        "    # \"He initialization\" method.\n",
        "    import math\n",
        "    stdv = 1.0 / math.sqrt(2048 * 1.0)\n",
        "\n",
        "    # 创建全连接层，输出大小为类别数目，经过残差网络的卷积和全局池化后，\n",
        "    # 卷积特征的维度是[B,2048,1,1]，故最后一层全连接的输入维度是2048\n",
        "    self.out=nn.Linear(in_features=2048,out_features=class_dim)\n",
        "    #The weights are initialized with a uniform distribution with range [-stdv, stdv] \n",
        "    #according to the previously calculated stdv.\n",
        "    #initialize weights\n",
        "    nn.init.uniform_(self.out.weight, -stdv, stdv)\n",
        "                     \n",
        "    \n",
        "    def forward(self,inputs):\n",
        "      y=self.conv(inputs)\n",
        "      y=self.pool2d_max(y)\n",
        "      for bottleneck_block in self.bottleneck_block_list:\n",
        "        y=bottleneck_block(y)\n",
        "      y=self.pool2d_avg(y)\n",
        "      y=torch.flatten(y, 1)\n",
        "      y=self.out(y)\n",
        "      return y\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "_mT5-NrABYoz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "# Call the resnet50 model using the torchvision library\n",
        "model = resnet50()\n",
        "# If you want to load the pretrained model on ImageNet dataset, use this instead:\n",
        "# model = resnet50(pretrained=True)\n",
        "\n",
        "# Randomly generate an input\n",
        "x = torch.rand([1, 3, 224, 224])\n",
        "# Get the output of the ResNet50 model\n",
        "out = model(x)\n",
        "# Print the shape of the output. As resnet50 is a 1000-class classifier by default,\n",
        "# the output shape is [1, 1000]\n",
        "print(out.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csgifP_3KDol",
        "outputId": "6f29b9b7-b047-4888-f2be-a8e698e5791a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, images are expected to be in (C, H, W) format (Channels, Height, Width), which is already reflected in the code above.\n",
        "\n",
        "You can use resnet50(pretrained=True) to get the ResNet50 model pretrained on ImageNet. If pretrained is False, the model will be initialized with random weights."
      ],
      "metadata": {
        "id": "Y3mGuhxvG9lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# Define the transformations - convert to tensor and normalize with mean and std from CIFAR10\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "# Load the CIFAR10 dataset\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "val_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create DataLoaders for training and validation sets\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=8)\n",
        "\n",
        "# Define the model, loss function, and optimizer\n",
        "model = resnet50(pretrained=False, num_classes=10)\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Lets us use GPU if available\n",
        "model = model.to(device)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(10):\n",
        "    model.train()  # Set the model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()  # Clear the gradients\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute the loss\n",
        "        loss.backward()  # Compute the gradients\n",
        "        optimizer.step()  # Update the weights\n",
        "    scheduler.step()  # Update the learning rate\n",
        "    \n",
        "    if (epoch+1) % 2 == 0:\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # Disable gradient calculation for efficiency\n",
        "            for images, labels in val_loader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(images)  # Forward pass\n",
        "                _, predicted = torch.max(outputs.data, 1)  # Get the predicted labels\n",
        "                total += labels.size(0)  # Increment the total count\n",
        "                correct += (predicted == labels).sum().item()  # Count the correct predictions\n",
        "\n",
        "        accuracy = correct / total  # Calculate the accuracy\n",
        "\n",
        "        print(f\"Accuracy at epoch {epoch}: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # You can also save your model periodically\n",
        "    torch.save(model.state_dict(), f\"./output/model_{epoch}.pth\")\n"
      ],
      "metadata": {
        "id": "lnXR4Pg_KIdL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script first loads and preprocesses the CIFAR10 dataset, then defines a ResNet50 model, a CrossEntropy loss function, and a stochastic gradient descent optimizer. The model is trained for 50 epochs. We use the StepLR learning rate scheduler, which multiplies the learning rate by 0.1 every 10 epochs.\n",
        "\n",
        "* To determine the number of batches, you can divide the total number of samples in your dataset by the batch_size. For example, if you have 10,000 samples and a batch_size of 64, you will have 10,000 / 64 = 156.25 batches. Note that the last batch may have a smaller size if the total number of samples is not divisible by the batch size.\n",
        "\n",
        "* `StepLR` is a learning rate scheduler provided by PyTorch. It is used to adjust the learning rate during training by multiplying it by a factor at specified intervals or epochs.\n",
        "\n",
        "The `StepLR` scheduler updates the learning rate according to the following formula:\n",
        "\n",
        "```python\n",
        "new_lr = lr * gamma\n",
        "```\n",
        "\n",
        "where `lr` is the current learning rate and `gamma` is the factor by which the learning rate is multiplied. This update is applied every `step_size` number of epochs.\n",
        "\n",
        "Here's an example of how to use `StepLR`:\n",
        "\n",
        "```python\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# Define the optimizer and initial learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Create the StepLR scheduler\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Train your model for each epoch\n",
        "\n",
        "    # Update the learning rate\n",
        "    scheduler.step()\n",
        "```\n",
        "\n",
        "In this example, the learning rate is reduced by a factor of `gamma=0.1` every `step_size=10` epochs. This means that the learning rate will be multiplied by `0.1` every 10 epochs, effectively decreasing it by 10 times.\n",
        "\n",
        "The `StepLR` scheduler is often used in combination with other training techniques to gradually decrease the learning rate over time. It can help improve convergence and fine-tune the model as training progresses. However, the specific values for `step_size` and `gamma` depend on the problem, dataset, and model architecture, and they may require experimentation to find the optimal values for your specific scenario.\n",
        "\n",
        "Finally, note that the DataLoader class in PyTorch automatically handles batching, shuffling, and parallel data loading."
      ],
      "metadata": {
        "id": "cCUGmgU1MqUv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eXOpOuLrMW91"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}